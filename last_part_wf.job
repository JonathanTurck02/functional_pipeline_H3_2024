#!/bin/bash
#SBATCH --export=NONE               # do not export current env to the job
#SBATCH --job-name=fin_process      # job name
#SBATCH --time=02:00:00             # max job run time dd-hh:mm:ss
#SBATCH --ntasks-per-node=1         # tasks (commands) per compute node
#SBATCH --cpus-per-task=24          # CPUs (threads) per command
#SBATCH --mem=360G                  # total memory per node
#SBATCH --output=stdout.%x.%j       # save stdout to file
#SBATCH --error=stderr.%x.%j        # save stderr to file





#### RUN HUMANN3 ####

module load GCC/11.2.0  OpenMPI/4.1.1
module load HUMAnN/3.8

mkdir -p out_humann

# Loop over each FASTQ file in the fastq_combine directory
for input_fastq in fastq_combine/*_hb_cb.fastq; do
    # Extract the sample name by removing the suffix
    sample_name=$(basename "${input_fastq}" _hb_cb.fastq)
    
    # Create an output directory for each sample
    sample_output_dir="out_humann/${sample_name}"
    mkdir -p "${sample_output_dir}"
    
    # Run HUMAnN on the input FASTQ file
    humann --input "${input_fastq}" \
           --output "${sample_output_dir}" \
           --threads "${SLURM_CPUS_PER_TASK}"
done

echo "WAR IS OVER"